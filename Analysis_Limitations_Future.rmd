---
title: "Investigating the theorized relationship between perceived risk and variance under CAPM"
author: "Jacob Han, Derrick Hee, Clayton Monis, and John Woolley"
date: "December 16, 2020"
indent: true
header-includes:
  - \setlength{\parindent}{4em}
  - \setlength{\parskip}{1em}
  - \usepackage{indentfirst}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

#Packages used in analysis
library(data.table)
library(knitr)

#Dataset
data = fread('W241 Final Project - Completed.csv')


#Histogram of Control Group
control_group = data[Treatment == 1, .(ref = Q2_1_1, obs = Q3_1_1, refdif = 100.37 - Q2_1_1, obsdif = 100.37 - Q3_1_1)]
control_group[, dif := obsdif - refdif]
hist_control<-hist(control_group$dif, breaks = 99)

#Histogram of High Variance
highvar_group = data[Treatment == 2, .(ref = Q2_1_1, obs = Q4_1_1, refdif = 100.37 - Q2_1_1, obsdif = 101.06 - Q4_1_1)]
highvar_group[, dif := obsdif - refdif]
highvar_combined = rbind(highvar_group, control_group)
hist_highvar<-hist(highvar_group$dif, breaks = 99)

#Histogram Left Skew
leftskew_group = data[Treatment == 3, .(ref = Q2_1_1, obs = Q5_1_1, refdif = 100.37 - Q2_1_1, obsdif = 100.42 - Q5_1_1)]
leftskew_group[, dif := obsdif - refdif]
leftskew_combined = rbind(leftskew_group, control_group)
hist_lskew<-hist(leftskew_group$dif, breaks = 99)

#Histogram Right Skew
rightskew_group = data[Treatment == 4 & is.na(Error), .(ref = Q2_1_1, obs = Q6_1_1, refdif = 100.37 - Q2_1_1, obsdif = 100.45 - Q6_1_1)]
rightskew_group[, dif := obsdif - refdif]
rightskew_combined = rbind(rightskew_group, control_group)
hist_rskew<-hist(rightskew_group$dif, breaks = 99)

#Random Inference High Variance
highvar_ate = highvar_group[, mean(dif)] - control_group[, mean(dif)]
highvar_list = c()
for(i in 1:1000){
  highvar_combined[, random := rbinom(.N, 1, highvar_group[, .N] / (highvar_group[, .N] + control_group[, .N]))]
  highvar_list[i] = highvar_combined[random == 1, mean(dif)] - highvar_combined[random == 0, mean(dif)]
}
ri_highvar<-hist(highvar_list, breaks = 20)
abline(v = highvar_ate)
highvar_p1 = sum(highvar_list > abs(highvar_ate) | highvar_list < -abs(highvar_ate)) / length(highvar_list)

#Random Inference Left Skew
leftskew_ate = leftskew_group[, mean(dif)] - control_group[, mean(dif)]
leftskew_list = c()
for(i in 1:1000){
  leftskew_combined[, random := rbinom(.N, 1, leftskew_group[, .N] / (leftskew_group[, .N] + control_group[, .N]))]
  leftskew_list[i] = leftskew_combined[random == 1, mean(dif)] - leftskew_combined[random == 0, mean(dif)]
}
ri_lskew<-hist(leftskew_list, breaks = 20)
abline(v = leftskew_ate)
leftskew_p = sum(leftskew_list > abs(leftskew_ate) | leftskew_list < -abs(leftskew_ate)) / length(leftskew_list)

#Random Inference Right Skew
rightskew_ate = rightskew_group[, mean(dif)] - control_group[, mean(dif)]
rightskew_list = c()
for(i in 1:1000){
  rightskew_combined[, random := rbinom(.N, 1, rightskew_group[, .N] / (rightskew_group[, .N] + control_group[, .N]))]
  rightskew_list[i] = rightskew_combined[random == 1, mean(dif)] - rightskew_combined[random == 0, mean(dif)]
}
ri_rskew<- hist(rightskew_list, breaks = 20)
abline(v = rightskew_ate)
rightskew_p = sum(rightskew_list > abs(rightskew_ate) | rightskew_list < -abs(rightskew_ate)) / length(rightskew_list)

#Percentage Identifying Table
pidt<-data.frame(
  "Partial ID" = c('-','46.67% (14/30)','43.75% (14/32)','50.00% (15/30)'),
  "Perfect ID" = c('18.75% (6/32)','33.33% (10/30)','12.50% (4/32)','16.67% (5/30)')
  )
row.names(pidt)<-c('Control','High Variance','Left-Skew','Right-Skew')

```

### Analysis  
  
The survey was set up to be active for a total of five days. At the end of this duration, a total of 903 individuals took the screening survey on Mechanical Turk. Of these 903, 598 respondents were screened out of the main survey by the aforementioned attention checks (176), or were otherwise deemed unfit for the main survey on the grounds of having not participated in online securities trading in the past five years (422). An additional 26 individuals were removed due to a failure to complete the screening survey. The rest of the 279 respondents were then sent a message containing an anonymous link to the main Qualtrics survey. A total of 153 respondents did not complete the main survey. 44 did not complete the main survey. 109 did not follow through to Qualtrics from the anonymous link given to them and were removed from the dataset. The remaining 126 respondents completed the survey. Two respondents received incorrect graphs for their treatment group and were removed. The rest were evenly divided into four groups (Control, High Variance, Left-Skew, Right-Skew). The group selection was made in the backend by Qualtrics’ pseudo-randomization algorithm before surveys were completed.  

![Dataset Breakdown](images/breakdown.png)  

Exploratory data analysis was first conducted on resulting data to query data quality. For each of the groups, the difference between question two (treatment) and question one (baseline) was calculated to determine the treatment effect for each respondent. These were then plotted as histograms to view the distribution of the population.  

```{r dist,fig.width=10,fig.height=10,fig.cap='Population distribution for (a) Control, (b) High Variance, (c) Left-Skew, (d) Right-Skew '}
#2x2 histogram
line = 1
cex = 2
side = 3
adj=-0.05

par(mfrow=c(2,2), oma=c(1,6,1,1))
hist(control_group$dif, breaks = 99, main='Control')
mtext("a)", side=side, line=line, adj=adj)
hist(highvar_group$dif, breaks = 99, main='High Variance')
mtext("b)", side=side, line=line, adj=adj)
hist(leftskew_group$dif, breaks = 99, main='Left-Skew')
mtext("c)", side=side, line=line, adj=adj)
hist(rightskew_group$dif, breaks = 99, main='Right-Skew')
mtext("d)", side=side, line=line, adj=adj)
mtext('figure label',side=1,outer=TRUE,line=1)
```

For the Control Group, both questions used the same graph with no variation or skewness. As a result, it would be expected that the respondents would reply with the same value for both questions, rendering the mean difference as zero. As seen in **Figure X** a, the majority of respondents had zero or close to zero mean deltas. However there are some outliers at -90 and -50 respectively. As a result, the average mean delta for the control group is -6.08. This was the first sign that the quality of respondents will need additional scrutiny. Similar outliers also appear in Left-Skew (**Figure X** c) and Right-Skew (**Figure X** d) groups.  

```{r}
kable(pidt,caption = "Percentage Identifying Treatment Condition",align="c")
```


Because of some of these suspicious answers, a follow-up examination of respondent comprehension was conducted using the results of the survey debriefing question. In this question, respondents were asked to identify the difference between the first and second graphs they were presented. The expectation was that respondents who understood the question and were able to interpret the graphs presented to them would be able to point out the differences between the graphs. However, as seen in **Table X**, the overall identification of treatment was very poor. As part of this analysis, perfect identification as well as partial identification were examined. A respondent was considered to have perfectly identified the treatment if they responded with only the factors that changed between their graphs. If they mentioned factors that did not change, they were placed into partial identification instead. Less than 50% of respondents correctly identified any factor that changed between graphs. This signaled that there were issues with the results that were collected. Either the respondents were unable to interpret the graphs given to them, or they had begun to fill out the survey on autopilot. Both of these scenarios will hinder the accuracy of the results. However we had no a priori principles by which to exclude outliers, therefore they were left in the study.

```{r ri,fig.width=10,fig.height=10,fig.cap='Randomization Inference '}
#2x2 histogram
line = 1
cex = 2
side = 3
adj=-0.05

par(mfrow=c(2,2), oma=c(1,6,1,1))
hist(highvar_list, breaks = 20, main='High Variance')
abline(v = highvar_ate)
mtext("a)", side=side, line=line, adj=adj)
mtext(paste(c('p =',highvar_p1),collapse=' '), side=side, line=line-5, adj=adj+.1)
hist(leftskew_list, breaks = 20, main='Left-Skew')
abline(v = leftskew_ate)
mtext(paste(c('p =',leftskew_p),collapse=' '), side=side, line=line-5, adj=adj+.1)
mtext("b)", side=side, line=line, adj=adj)
hist(rightskew_list, breaks = 20, main='Right-Skew')
abline(v = rightskew_ate)
mtext(paste(c('p =',rightskew_p),collapse=' '), side=side, line=line-5, adj=adj+.1)
mtext("c)", side=side, line=line, adj=adj)
mtext('figure label',side=1,outer=TRUE,line=1)
```

Randomization inference was used to generate p-values for each of the treatment conditions in comparison to control. Of High Variance (**Figure X**), Left-Skew (**Figure X**) and Right-Skew (**figure**), both Left-Skew (0.047) and Right-Skew (0.014) returned significant p-values at the 95% confidence level. Additionally, pairwise t-tests (**Table**) were also conducted on the samples. We report Bonferroni adjusted p-values. When uncorrected, both Left-Skew and Right-Skew t-tests returned significant p-values at the 95% confidence level. However when corrected, neither were significant.  

# TODO Make pairwise bonferroni corrected tables

## Limitations

Through the course of the experiment, there were a number of platform limitations in both platforms used to conduct the survey, Mechanical Turk and Qualtrics. Many of the issues lead to an increase in respondents attriting (*figure**) between surveys or half-way through a survey. Had these limitations been known beforehand, the experiment design could have been adjusted to accommodate. Unfortunately these limitations were discovered while conducting the experiment.  

Mechanical Turk is subject to factors outside of experimental control. For example, surveys on Mechanical Turk are often subject to peer review. External websites like TurkOpticon are filled with users who post reviews for surveys being hosted on Mechanical Turk. These can act as positive or negative incentives for users on the platform. For example if a survey has overly negative reviews like “Too complicated for compensation offered”, other users will be disincentivized from attempting the survey. This effect is not consistent across the entire Mechanical Turk population either, as these are external review sites that not all users will use. Additionally, it is unfeasible to track the rating of this experiment’s survey across all the variety of Mechanical Turk survey review sites to ensure zero effect.  

This experiment was also limited by the compensation that was offered. With a budget of $500, each respondent was offered $0.70 - $1.10. For a survey dealing with mathematics and thought intensive questions, the survey may inch into the “too troublesome” category for most respondents. As the experiment filtered for American residents, the demographic (**citation**) of respondents would be people who consider Mechanical Turk as a secondary source of income. There will be additional bias introduced by attrition from users who feel the survey is not worth the compensation offered based on the time that is needed to complete the survey. For other users, the poor compensation could also lead to autopilot survey responses or thoughtless answers, which is poor data for drawing conclusions from.  

In addition to the attrition from poor compensation, the utilization of two separate platforms for the experiment proved to be a big source of attrition. Nearly half the respondents who passed the screening survey (109/279) on Mechanical Turk did not follow through to Qualtrics to complete the main survey. This may also be related to poor compensation. Doubtless there are many one part jobs that offer the same amount of compensation as this experiment. The hassle of switching to a new website also contributes to the attrition rate.  

Qualtrics also had its own share of shortcomings. The survey link to Qualtrics was an anonymous link. This caused issues when respondents left the survey midway through. When they returned, Qualtrics considered them as a new responder. Since we cannot distinguish between individuals who left and those who left but later completed the survey, attrition estimates for respondents who did not complete the survey are not very accurate. Qualtrics also employs pseudo random assignments to fill groups. As groups fill up, some positive adjustments are applied to less full groups in order to match the other groups. As a result there will be some time effects involved with treatment assignment. Additionally, respondents who leave partway through the survey can be assigned a different treatment each time they enter the survey.  

After the survey results were collected, the quality of responses were also brought into question. As mentioned previously, there were some suspicious responses to all parts of the main survey. Besides the illogical responses, it was clear that not all respondents may have understood the question being posed from analysis of the survey debriefing. This is likely a combination of bad faith responses not being filtered and poor understanding of the questions being posed. As a result, the results of the experiment are also drawn into question.  

## Future Directions

The fundamental structure of the survey will likely need to be changed. As seen from the survey responses, the majority of respondents had no stake in the problem. With a fake scenario with fake money on the line, it is no wonder that there were joke responses mixed into the results. Having some stakes built into the survey would help gather serious responses. The obvious answer would be to give respondents money to invest in the stock market with the promise of giving them whatever they make over the course of the experiment. However this will bring up ethical concerns, where we are directly altering the distributions of returns while retaining profit and loss for the respondents.  

Another possibility of raising stakes would be tying compensation amount to performance. In this scenario, the experiment would be set up to have four dummy stocks in which respondents will be able to invest their pseudo-currency. Before the experiment, the respondents will be notified that their compensation will be tied to their performance. This will serve as a motivation to properly tackle the problems being posed.  

In order to collect reliable data, the survey will need to be adjusted to better identify individuals who do not understand the concepts being presented to them. As seen from the debriefing results, the single statistics and risk analysis filtering question was not able to ensure that respondents could interpret the graphs given to them. The addition of questions asking respondents to glean information from the graph (such as quartile, mean, skew) would serve as a method to determine comprehension.  

The typical demographic(**citation**) for Mechanical Turk users are younger people with lower incomes that use Mechanical Turk as a secondary source of income. Therefore the typical population of respondents will be people who do not have the luxury of investing into stocks and gaining experience. With the level of compensation offered on Mechanical Turk, the chances of gathering a sample with a high proportion of individuals with sophisticated understanding of financial economics is quite low. The typical experiment would thus consist of this demographic and not be representative of the population as a whole. This problem can also be solved by choosing a population of individuals who would understand, such as college-educated economics students or those who work in the industry.  

# TODO: Auction Format

When considering the population of the study, another fundamental question needs to be answered: is it important for the average person to understand the concepts of CAPM? It can be argued that CAPM only needs to be followed by the people at the top who move large amounts of money in the market. That it doesn’t matter if the average person who sometimes performs market transactions does not follow this principle as long as the majority of transactions in the market do. Therefore, rather than querying the general population, market makers or managers of large asset portfolios would be the more appropriate audience than the general population of traders for such an experiment.  

## Citations

- MTurk Demographics - https://www.ipeirotis.com/wp-content/uploads/2017/12/wsdmf074-difallahA.pdf


